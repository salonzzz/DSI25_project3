{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "**Contents**\n",
    "1. Problem Statement\n",
    "2. Importing libraries\n",
    "3. Retrieve Data from Alcoholic Anonymous Subreddit\n",
    "4. Retrieve Data from Stop Smoking Subreddit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "\n",
    "Due to the COVID-19 pandemic, the ability to physcially visit facilities of any nature have become limited. Specifically, one's ability to walk into a rehabilitative facility on a whim is no longer a possibility without first being tested negative for COVID. This really de-motivates people from seeking help since their needs cannot be catered to instatenously anymore and the expected delays often put people off from seeking help altogether. \n",
    "\n",
    "People are cooped up at home more now and it is no surprise that the stress of having to live through such unprecedented times is catching up. People are drinking, smoking, abusing drugs more with little to no other avenues to cope with the novel situation and it is easy to go down the slippery slope of addiction. \n",
    "\n",
    "People who are able to catch on that they are becoming addicted to a substance often do want to seek help but given the lack of ease in seeking helping physically in these pandemic times, recovering addicts have turned to social media platforms such as reddit to air their concerns. While doing so allows them to offer recovery aid peer to peer, it still does not allow them to access professional resources just as easily.\n",
    "\n",
    "Rehabilitative facilites, as a result, have reached out to our team of data scientists and tasked us to identify people seeking aid for addiction and specifically seeking aid to curb a smoking or drinking problem. Avenues to help are available but there is a lack of means to access professional services that can help addicts just as well as a physical visit to a rehabilitative centre might. We aim to create an online chatbox for these rehabilitative facilities such that any query put in by a user in the chatbox can instantenously be identified as a smoking or drinking problem based on the keywords being used in the query and within seconds users can be redirected to targetted professional aid to guide them along their path to recovery during these unprecedented times. \n",
    "\n",
    "### The process of addressing the problem statement\n",
    "\n",
    "This details the process of creating the chatbox. 2000 posts will be scraped from subreddits r/stopsmoking and r/alcoholicsanonymous. These datasets will then be checked for duplicate posts, unwanted characters like emojis, and URLs. Identified duplicate rows will be dropped and unwanted charcters and URLs will be scrubbed from the title and selftext columns. All other columns will be dropped as we want to focus on using text posts for this classification task. A new column combinign the title and selftext will be created so as to encompass all text from a post. This will be used in our modelling process. The r/alcoholicsanonymous and r/stopsomking datasets will then first be encoded as 0 and 1 respectively before being merged.The data will then undergo pre-processing which involves removing stop words, tokenizing words and lemmatizing them. After some explaratory data analysis to attain preliminary insights, the data will be fitted and classification models such as Naive Bayes, KNearestNeighbour and Logistic Regression, will be trained on the data such that they are able to classify whether a post is from r/stopsmoking or r/alcoholics anonymous respectively when it comes to unseen data/posts. The best model or most accurate model (based on metrics such as the R2 score or Area under the curve score) to predict whether a post is made by a recovering smoker or alcoholic will then be used to construct a chatbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from Alcoholic Anonymous Subreddit\n",
    "\n",
    "We will be using the PushShift API to pull data out from our subreddits. Lets start by pulling out the data from the alcoholics subreddit.\n",
    "\n",
    "Note that PushShift API does not allow pulling above 100 subreddits, thus we have to make muitiple requests to get our data scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for PushShift API to retrieve the data from the Alcoholic Anonymous subreddit\n",
    "params = {\n",
    "    'subreddit': 'alcoholicsanonymous', 'size': '100'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 70 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  2000 non-null   object \n",
      " 1   allow_live_comments            2000 non-null   bool   \n",
      " 2   author                         2000 non-null   object \n",
      " 3   author_flair_css_class         0 non-null      object \n",
      " 4   author_flair_richtext          1991 non-null   object \n",
      " 5   author_flair_text              0 non-null      object \n",
      " 6   author_flair_type              1991 non-null   object \n",
      " 7   author_fullname                1991 non-null   object \n",
      " 8   author_is_blocked              2000 non-null   bool   \n",
      " 9   author_patreon_flair           1991 non-null   object \n",
      " 10  author_premium                 1991 non-null   object \n",
      " 11  awarders                       2000 non-null   object \n",
      " 12  can_mod_post                   2000 non-null   bool   \n",
      " 13  contest_mode                   2000 non-null   bool   \n",
      " 14  created_utc                    2000 non-null   int64  \n",
      " 15  domain                         2000 non-null   object \n",
      " 16  full_link                      2000 non-null   object \n",
      " 17  gildings                       2000 non-null   object \n",
      " 18  id                             2000 non-null   object \n",
      " 19  is_created_from_ads_ui         2000 non-null   bool   \n",
      " 20  is_crosspostable               2000 non-null   bool   \n",
      " 21  is_meta                        2000 non-null   bool   \n",
      " 22  is_original_content            2000 non-null   bool   \n",
      " 23  is_reddit_media_domain         2000 non-null   bool   \n",
      " 24  is_robot_indexable             2000 non-null   bool   \n",
      " 25  is_self                        2000 non-null   bool   \n",
      " 26  is_video                       2000 non-null   bool   \n",
      " 27  link_flair_background_color    2000 non-null   object \n",
      " 28  link_flair_richtext            2000 non-null   object \n",
      " 29  link_flair_text_color          2000 non-null   object \n",
      " 30  link_flair_type                2000 non-null   object \n",
      " 31  locked                         2000 non-null   bool   \n",
      " 32  media_only                     2000 non-null   bool   \n",
      " 33  no_follow                      2000 non-null   bool   \n",
      " 34  num_comments                   2000 non-null   int64  \n",
      " 35  num_crossposts                 2000 non-null   int64  \n",
      " 36  over_18                        2000 non-null   bool   \n",
      " 37  parent_whitelist_status        1985 non-null   object \n",
      " 38  permalink                      2000 non-null   object \n",
      " 39  pinned                         2000 non-null   bool   \n",
      " 40  pwls                           1985 non-null   float64\n",
      " 41  retrieved_on                   2000 non-null   int64  \n",
      " 42  score                          2000 non-null   int64  \n",
      " 43  selftext                       1999 non-null   object \n",
      " 44  send_replies                   2000 non-null   bool   \n",
      " 45  spoiler                        2000 non-null   bool   \n",
      " 46  stickied                       2000 non-null   bool   \n",
      " 47  subreddit                      2000 non-null   object \n",
      " 48  subreddit_id                   2000 non-null   object \n",
      " 49  subreddit_subscribers          2000 non-null   int64  \n",
      " 50  subreddit_type                 2000 non-null   object \n",
      " 51  thumbnail                      2000 non-null   object \n",
      " 52  title                          2000 non-null   object \n",
      " 53  total_awards_received          2000 non-null   int64  \n",
      " 54  treatment_tags                 2000 non-null   object \n",
      " 55  upvote_ratio                   2000 non-null   float64\n",
      " 56  url                            2000 non-null   object \n",
      " 57  whitelist_status               1985 non-null   object \n",
      " 58  wls                            1985 non-null   float64\n",
      " 59  removed_by_category            59 non-null     object \n",
      " 60  crosspost_parent               9 non-null      object \n",
      " 61  crosspost_parent_list          9 non-null      object \n",
      " 62  url_overridden_by_dest         9 non-null      object \n",
      " 63  post_hint                      138 non-null    object \n",
      " 64  preview                        138 non-null    object \n",
      " 65  author_flair_background_color  9 non-null      object \n",
      " 66  author_flair_text_color        9 non-null      object \n",
      " 67  author_cakeday                 6 non-null      object \n",
      " 68  edited                         6 non-null      float64\n",
      " 69  banned_by                      1 non-null      object \n",
      "dtypes: bool(20), float64(4), int64(7), object(39)\n",
      "memory usage: 820.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_alc_anon = pd.DataFrame()\n",
    "total_data = 0\n",
    "last = 0\n",
    "# Initialise our memory variables\n",
    "\n",
    "while total_data < 2000:\n",
    "    if last == 0: # This means it is a fresh run of the loop and thus 'before' parameter should be omitted\n",
    "        params.pop('before', None)\n",
    "    else:\n",
    "        params['before'] = last \n",
    "        # There was a previous entry from PushShift API into our DataFrame, set 'before' to the previous oldest entry\n",
    "        \n",
    "    response = requests.get(url, params) # Get a response from PushShift API\n",
    "    data = response.json() # Send our PushShift response into a json decoder\n",
    "    post = pd.DataFrame(data ['data']) # Send the decoded data into our post DataFrame object\n",
    "    df_alc_anon = pd.concat([df_alc_anon, post]) # Concatenate the old and new DataFrames together with the new one underneath.\n",
    "    total_data += len(post) # Add our counter based on the number of posts we retrieved in post\n",
    "    df_alc_anon.sort_values(by = 'created_utc', ascending = False, inplace = True) # sort data by their post time\n",
    "    last = int(df_alc_anon['created_utc'].iloc[-1:]) # set our last time for our next loop\n",
    "\n",
    "df_alc_anon.reset_index(drop = True, inplace = True) # The index will be screwed during the loop, reindex to maintain continuity\n",
    "df_alc_anon.info() # Review our Data Retrieval to ensure it is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Pulled Alcoholics Data into CSV\n",
    "With our data with us, let's save our data into the appropriate CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data into csv\n",
    "try: \n",
    "    df_alc_anon.to_csv('../data/alcoholicsanonymous_raw.csv')\n",
    "except:\n",
    "    print('alcoholicsanonymous_raw.csv is currently open with another program, please rerun code cell again after closing the other program.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from Stop Smoking Subreddit\n",
    "With our alcoholics data in, now we need our smoking subreddit data. Let's pull out data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for PushShift API to retrieve the data from the Alcoholic Anonymous subreddit\n",
    "params = {\n",
    "    'subreddit': 'stopsmoking', 'size': '100'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 81 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  2000 non-null   object \n",
      " 1   allow_live_comments            2000 non-null   bool   \n",
      " 2   author                         2000 non-null   object \n",
      " 3   author_flair_css_class         197 non-null    object \n",
      " 4   author_flair_richtext          1993 non-null   object \n",
      " 5   author_flair_text              197 non-null    object \n",
      " 6   author_flair_type              1993 non-null   object \n",
      " 7   author_fullname                1993 non-null   object \n",
      " 8   author_is_blocked              2000 non-null   bool   \n",
      " 9   author_patreon_flair           1993 non-null   object \n",
      " 10  author_premium                 1993 non-null   object \n",
      " 11  awarders                       2000 non-null   object \n",
      " 12  can_mod_post                   2000 non-null   bool   \n",
      " 13  contest_mode                   2000 non-null   bool   \n",
      " 14  created_utc                    2000 non-null   int64  \n",
      " 15  domain                         2000 non-null   object \n",
      " 16  full_link                      2000 non-null   object \n",
      " 17  gildings                       2000 non-null   object \n",
      " 18  id                             2000 non-null   object \n",
      " 19  is_created_from_ads_ui         2000 non-null   bool   \n",
      " 20  is_crosspostable               2000 non-null   bool   \n",
      " 21  is_meta                        2000 non-null   bool   \n",
      " 22  is_original_content            2000 non-null   bool   \n",
      " 23  is_reddit_media_domain         2000 non-null   bool   \n",
      " 24  is_robot_indexable             2000 non-null   bool   \n",
      " 25  is_self                        2000 non-null   bool   \n",
      " 26  is_video                       2000 non-null   bool   \n",
      " 27  link_flair_background_color    2000 non-null   object \n",
      " 28  link_flair_richtext            2000 non-null   object \n",
      " 29  link_flair_text_color          2000 non-null   object \n",
      " 30  link_flair_type                2000 non-null   object \n",
      " 31  locked                         2000 non-null   bool   \n",
      " 32  media_only                     2000 non-null   bool   \n",
      " 33  no_follow                      2000 non-null   bool   \n",
      " 34  num_comments                   2000 non-null   int64  \n",
      " 35  num_crossposts                 2000 non-null   int64  \n",
      " 36  over_18                        2000 non-null   bool   \n",
      " 37  parent_whitelist_status        1981 non-null   object \n",
      " 38  permalink                      2000 non-null   object \n",
      " 39  pinned                         2000 non-null   bool   \n",
      " 40  pwls                           1981 non-null   float64\n",
      " 41  retrieved_on                   2000 non-null   int64  \n",
      " 42  score                          2000 non-null   int64  \n",
      " 43  selftext                       1999 non-null   object \n",
      " 44  send_replies                   2000 non-null   bool   \n",
      " 45  spoiler                        2000 non-null   bool   \n",
      " 46  stickied                       2000 non-null   bool   \n",
      " 47  subreddit                      2000 non-null   object \n",
      " 48  subreddit_id                   2000 non-null   object \n",
      " 49  subreddit_subscribers          2000 non-null   int64  \n",
      " 50  subreddit_type                 2000 non-null   object \n",
      " 51  thumbnail                      2000 non-null   object \n",
      " 52  title                          2000 non-null   object \n",
      " 53  total_awards_received          2000 non-null   int64  \n",
      " 54  treatment_tags                 2000 non-null   object \n",
      " 55  upvote_ratio                   2000 non-null   float64\n",
      " 56  url                            2000 non-null   object \n",
      " 57  whitelist_status               1981 non-null   object \n",
      " 58  wls                            1981 non-null   float64\n",
      " 59  crosspost_parent               20 non-null     object \n",
      " 60  crosspost_parent_list          20 non-null     object \n",
      " 61  url_overridden_by_dest         386 non-null    object \n",
      " 62  post_hint                      390 non-null    object \n",
      " 63  preview                        390 non-null    object \n",
      " 64  thumbnail_height               379 non-null    float64\n",
      " 65  thumbnail_width                379 non-null    float64\n",
      " 66  removed_by_category            55 non-null     object \n",
      " 67  author_flair_template_id       197 non-null    object \n",
      " 68  author_flair_text_color        218 non-null    object \n",
      " 69  media                          13 non-null     object \n",
      " 70  media_embed                    12 non-null     object \n",
      " 71  secure_media                   13 non-null     object \n",
      " 72  secure_media_embed             12 non-null     object \n",
      " 73  media_metadata                 23 non-null     object \n",
      " 74  author_cakeday                 7 non-null      object \n",
      " 75  gallery_data                   12 non-null     object \n",
      " 76  is_gallery                     13 non-null     object \n",
      " 77  author_flair_background_color  21 non-null     object \n",
      " 78  poll_data                      5 non-null      object \n",
      " 79  edited                         2 non-null      float64\n",
      " 80  banned_by                      1 non-null      object \n",
      "dtypes: bool(20), float64(6), int64(7), object(48)\n",
      "memory usage: 992.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stop_smoking = pd.DataFrame()\n",
    "total_data = 0\n",
    "last = 0\n",
    "# Initialise our memory variables\n",
    "\n",
    "while total_data < 2000:\n",
    "    if last == 0: # This means it is a fresh run of the loop and thus 'before' parameter should be omitted\n",
    "        params.pop('before', None)\n",
    "    else:\n",
    "        params ['before'] = last \n",
    "        # There was a previous entry from PushShift API into our DataFrame, set 'before' to the previous oldest entry\n",
    "        \n",
    "    response = requests.get(url, params) # Get a response from PushShift API\n",
    "    data = response.json() # Send our PushShift response into a json decoder\n",
    "    post = pd.DataFrame(data ['data']) # Send the decoded data into our post DataFrame object\n",
    "    df_stop_smoking = pd.concat([df_stop_smoking, post]) # Concatenate the old and new DataFrames together with the new one underneath.\n",
    "    total_data += len(post) # Add our counter based on the number of posts we retrieved in post\n",
    "    df_stop_smoking.sort_values(by = 'created_utc', ascending = False, inplace = True) # sort data by their post time\n",
    "    last = int(df_stop_smoking['created_utc'].iloc[-1:]) # set our last time for our next loop\n",
    "\n",
    "df_stop_smoking.reset_index(drop = True, inplace = True) # The index will be screwed during the loop, reindex to maintain continuity\n",
    "df_stop_smoking.info() # Review our Data Retrieval to ensure it is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Pulled Smoking Data into CSV\n",
    "With our data with us, let's save our data into the appropriate CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data into csv\n",
    "df_stop_smoking.to_csv('../data/stopsmoking_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Data Retrieval\n",
    "With our data scraped, we can proceed to the next portion of our analysis which is to clean the data. This will be done on the data cleaning notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
